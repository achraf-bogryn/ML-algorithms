{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Part Of Speech Tags\n",
        "\n",
        "* CC coordinate Conjunction\n",
        "* CD cardinal digit\n",
        "* DT determiner\n",
        "* EX existential there (exp : there is , ...)\n",
        "* FW foreign words\n",
        "* IN preposition/subordinating conjunction\n",
        "* JJ adjective\n",
        "* JJR adjectivec, comparative - 'Bigger'\n",
        "* JJS adjective , superlative  -'biggest'\n",
        "* LS list market 1\n",
        "* MD modal - could , will\n",
        "* NN noun , singular , '-desk'\n",
        "* NNS noun plural - 'desks'"
      ],
      "metadata": {
        "id": "6Tgoicddiuo_"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "MeZrqyg8ietJ"
      },
      "outputs": [],
      "source": [
        "paragraph = '''\n",
        "The Amazon rainforest, often referred to as the lungs of the Earth, is the largest tropical rainforest in the world. It covers over 5.5 million square kilometers across nine countries in South America. Rich in biodiversity, the forest is home to more than 3 million species of plants and animals. Unfortunately, deforestation and climate change pose serious threats to its delicate ecosystem.\n",
        "'''"
      ]
    },
    {
      "source": [
        "import nltk\n",
        "from nltk.stem import PorterStemmer\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "# Download the required NLTK resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "\n",
        "\n",
        "stemmer = PorterStemmer()\n",
        "sentence = nltk.sent_tokenize(paragraph)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Um4W2pnOna6m",
        "outputId": "67f0cf09-1fc4-414b-f6f3-34f384e840be"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for word in sentence:\n",
        "  print(word)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng1SgnygoPef",
        "outputId": "3e0a2993-e0ca-43d7-a4a1-62eb6522401e"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the amazon rainforest , often refer lung earth , largest tropic rainforest world .\n",
            "it cover 5.5 million squar kilomet across nine countri south america .\n",
            "rich biodivers , forest home 3 million speci plant anim .\n",
            "unfortun , deforest climat chang pose seriou threat delic ecosystem .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Apply stopwords to find pos tag"
      ],
      "metadata": {
        "id": "SMr9CjIJnpKG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "# Download the 'averaged_perceptron_tagger' resource\n",
        "nltk.download('averaged_perceptron_tagger')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tkxTnu99qnMf",
        "outputId": "819f99e4-648b-42c8-c909-e9e63d3efb56"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will find the pos tag\n",
        "for i in range(len(sentence)):\n",
        "  words = nltk.word_tokenize(sentence[i])\n",
        "  words = [word for word in words if word not in set(stopwords.words('english'))]\n",
        "  # sentence[i] =' '.join(words)\n",
        "  pos_tag = nltk.pos_tag(words)\n",
        "  print(pos_tag)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yg8B7uLxnw8X",
        "outputId": "706341b7-48ad-4a5b-f3fa-c2ba962ea9c2"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('The', 'DT'), ('Amazon', 'NNP'), ('rainforest', 'NN'), (',', ','), ('often', 'RB'), ('referred', 'JJ'), ('lungs', 'NNS'), ('Earth', 'NNP'), (',', ','), ('largest', 'JJS'), ('tropical', 'JJ'), ('rainforest', 'NN'), ('world', 'NN'), ('.', '.')]\n",
            "[('It', 'PRP'), ('covers', 'VBZ'), ('5.5', 'CD'), ('million', 'CD'), ('square', 'JJ'), ('kilometers', 'NNS'), ('across', 'IN'), ('nine', 'CD'), ('countries', 'NNS'), ('South', 'NNP'), ('America', 'NNP'), ('.', '.')]\n",
            "[('Rich', 'JJ'), ('biodiversity', 'NN'), (',', ','), ('forest', 'VBP'), ('home', 'NN'), ('3', 'CD'), ('million', 'CD'), ('species', 'NNS'), ('plants', 'NNS'), ('animals', 'NNS'), ('.', '.')]\n",
            "[('Unfortunately', 'RB'), (',', ','), ('deforestation', 'NN'), ('climate', 'NN'), ('change', 'NN'), ('pose', 'VBP'), ('serious', 'JJ'), ('threats', 'NNS'), ('delicate', 'VBP'), ('ecosystem', 'NN'), ('.', '.')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pos_tag"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0hLXYYnndrD",
        "outputId": "73959ce1-a307-4ee1-dac6-3b900e688bb6"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Unfortunately', 'RB'),\n",
              " (',', ','),\n",
              " ('deforestation', 'NN'),\n",
              " ('climate', 'NN'),\n",
              " ('change', 'NN'),\n",
              " ('pose', 'VBP'),\n",
              " ('serious', 'JJ'),\n",
              " ('threats', 'NNS'),\n",
              " ('delicate', 'VBP'),\n",
              " ('ecosystem', 'NN'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.pos_tag_sents(\"Morocco is a beautiful country\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "AuRoFNiNuY3n",
        "outputId": "ee4acc04-8cc4-478c-e53e-27efff637bed"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "tokens: expected a list of strings, got a string",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-29-7d6365cbaf8c>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_tag_sents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Morocco is a beautiful country\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36mpos_tag_sents\u001b[0;34m(sentences, tagset, lang)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \"\"\"\n\u001b[1;32m    186\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    185\u001b[0m     \"\"\"\n\u001b[1;32m    186\u001b[0m     \u001b[0mtagger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_tagger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_pos_tag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtagger\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msentences\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/nltk/tag/__init__.py\u001b[0m in \u001b[0;36m_pos_tag\u001b[0;34m(tokens, tagset, tagger, lang)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;31m# Throws Error if tokens is of string type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 123\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"tokens: expected a list of strings, got a string\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    124\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: tokens: expected a list of strings, got a string"
          ]
        }
      ]
    },
    {
      "source": [
        "import nltk\n",
        "\n",
        "# Tokenize the sentence into a list of words\n",
        "sentence = \"Taj and Morocco is a beautiful country\".split()\n",
        "\n",
        "# Create a list of sentences, even if you only have one\n",
        "sentences = [sentence]\n",
        "\n",
        "# Now you can use pos_tag_sents\n",
        "tagged_sentences = nltk.pos_tag_sents(sentences)\n",
        "print(tagged_sentences)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OIY4RacFuufp",
        "outputId": "49d372a2-5887-4edb-e482-9469466e8f60"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[('Taj', 'NNP'), ('and', 'CC'), ('Morocco', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('country', 'NN')]]\n"
          ]
        }
      ]
    },
    {
      "source": [
        "import nltk\n",
        "\n",
        "# Tokenize the sentence into a list of words\n",
        "sentence = \"Taj and Morocco is a beautiful country\".split()\n",
        "\n",
        "# You don't need to create a nested list, just pass the 'sentence' list directly.\n",
        "tagged_sentences = nltk.pos_tag(sentence)\n",
        "print(tagged_sentences)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4lOe3_SjvlXX",
        "outputId": "95d25b9a-0efb-4a9d-8611-6d46a2ca5802"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('Taj', 'NNP'), ('and', 'CC'), ('Morocco', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('country', 'NN')]\n"
          ]
        }
      ]
    }
  ]
}